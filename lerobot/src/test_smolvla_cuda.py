#!/usr/bin/env python3
"""
SmolVLA CUDA í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import os
import sys

def test_cuda_environment():
    """CUDA í™˜ê²½ í…ŒìŠ¤íŠ¸"""
    print("=== CUDA í™˜ê²½ í…ŒìŠ¤íŠ¸ ===")
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA version: {torch.version.cuda}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"Device count: {torch.cuda.device_count()}")
        print(f"Current device: {torch.cuda.current_device()}")
        print(f"Device name: {torch.cuda.get_device_name()}")
        print(f"Device capability: {torch.cuda.get_device_capability()}")
        
        # ê¸°ë³¸ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸
        try:
            x = torch.randn(10, 10).cuda()
            y = torch.randn(10, 10).cuda()
            z = torch.matmul(x, y)
            print("âœ… ê¸°ë³¸ CUDA ì—°ì‚° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ CUDA ì—°ì‚° ì‹¤íŒ¨: {e}")
            return False
    
    return True

def test_smolvla_loading():
    """SmolVLA ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    print("\n=== SmolVLA ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ===")
    
    # CUDA ì„¤ì • ìµœì í™”
    torch.backends.cudnn.benchmark = True
    torch.cuda.empty_cache()
    
    try:
        from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
        
        print("SmolVLA ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
        
        # ë°©ë²• 1: ê¸°ë³¸ GPU ë¡œë“œ
        policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
        
        print("âœ… SmolVLA ëª¨ë¸ì´ GPUì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ëª¨ë¸ íƒ€ì…: {type(policy)}")
        return policy
        
    except Exception as e:
        print(f"âŒ ê¸°ë³¸ GPU ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: auto device mapping ì‹œë„
        try:
            print("\nAuto device mappingìœ¼ë¡œ ì¬ì‹œë„...")
            policy = SmolVLAPolicy.from_pretrained(
                "lerobot/smolvla_base",
                device_map="auto",
                torch_dtype=torch.float16
            )
            print("âœ… Auto device mappingìœ¼ë¡œ ì„±ê³µ!")
            return policy
            
        except Exception as e2:
            print(f"âŒ Auto device mapping ì‹¤íŒ¨: {e2}")
            
            # ë°©ë²• 3: CPU ëª¨ë“œ ì‹œë„
            try:
                print("\nCPU ëª¨ë“œë¡œ ì¬ì‹œë„...")
                os.environ['CUDA_VISIBLE_DEVICES'] = ''
                policy = SmolVLAPolicy.from_pretrained(
                    "lerobot/smolvla_base", 
                    device_map="cpu"
                )
                print("âœ… CPU ëª¨ë“œë¡œ ì„±ê³µ!")
                return policy
                
            except Exception as e3:
                print(f"âŒ CPU ëª¨ë“œ ì‹¤íŒ¨: {e3}")
                return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("SmolVLA CUDA í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # CUDA í™˜ê²½ í…ŒìŠ¤íŠ¸
    if not test_cuda_environment():
        print("CUDA í™˜ê²½ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        return
    
    # SmolVLA ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    policy = test_smolvla_loading()
    
    if policy:
        print(f"\nğŸ‰ ì„±ê³µ! ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ëª¨ë¸ íƒ€ì…: {type(policy)}")
    else:
        print(f"\nâŒ ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("PyTorch ë²„ì „ì´ë‚˜ CUDA ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
